---
title: 大模型系列——RAG 入门与技术演进
published: 2025-12-03
description: 系统梳理检索增强生成（RAG）的核心定义、原理、演进与选型策略。
tags: [大模型, RAG, AI, 检索增强生成]
category: RAG
lang: zh_CN
draft: false
---

# 大模型系列——RAG 入门与技术演进

## 一、什么是 RAG？
### 1.1 核心定义
从本质上讲，RAG（Retrieval-Augmented Generation）是一种旨在解决大语言模型（LLM）“知其然不知其所以然”问题的技术范式。它的核心是将模型内部学到的“参数化知识”（模型权重中固化的、模糊的“记忆”），与来自外部知识库的“非参数化知识”（精准、可随时更新的外部数据）相结合。
其运作逻辑就是在 LLM 生成文本前，先通过检索机制从外部知识库中动态获取相关信息，并将这些“参考资料”融入生成过程，从而提升输出的准确性和时效性。

💡 一句话总结：RAG 就是让 LLM 学会了“开卷考试”，它既能利用自己学到的知识，也能随时查阅外部资料。

### 1.2 技术原理
RAG 系统的架构主要通过两个阶段来完成这一过程：

**检索阶段：寻找“非参数化知识”**

- 知识向量化：嵌入模型（Embedding Model）充当了“连接器”的角色。它将外部知识库编码为向量索引（Index），存入向量数据库。
- 语义召回：当用户发起查询时，检索模块利用同样的嵌入模型将问题向量化，并通过相似度搜索（Similarity Search），从海量数据中精准锁定与问题最相关的文档片段。

**生成阶段：融合两种知识**

- 上下文整合：生成模块接收检索阶段送来的相关文档片段以及用户的原始问题。
- 指令引导生成：该模块会遵循预设的 Prompt 指令，将上下文与问题有效整合，并引导 LLM 进行可控的、有理有据的文本生成。

### 1.3 技术演进分类
RAG 的技术架构经历了从简单到复杂的演进，大致可分为三个阶段：

| 阶段 | 流程 | 特点 | 关键技术 | 局限性 |
|------|------|------|----------|--------|
| 初级 RAG（Naive RAG） | 离线: 索引<br>在线: 检索 → 生成 | 基础线性流程 | 基础向量检索 | 效果不稳定，难以优化 |
| 高级 RAG（Advanced RAG） | 离线: 索引<br>在线: ...→ 检索前 → ... → 检索后 → ... | 增加检索前后的优化步骤 | 查询重写（Query Rewrite）<br>结果重排（Rerank） | 流程相对固定，优化点有限 |
| 模块化 RAG（Modular RAG） | 积木式可编排流程 | 模块化、可组合、可动态调整 | 动态路由（Routing）<br>查询转换（Query Transformation）<br>多路融合（Fusion） | 系统复杂性高 |

"离线"指提前完成的数据预处理工作（如索引构建）；"在线"指用户发起请求后的实时处理流程。

## 二、为什么要使用 RAG？
### 2.1 技术选型：RAG vs. 微调
在选择具体的技术路径时，一个重要的考量是成本与效益的平衡。通常，我们应优先选择对模型改动最小、成本最低的方案，所以技术选型路径往往遵循的顺序是：

**提示词工程（Prompt Engineering） -> 检索增强生成 -> 微调（Fine-tuning）**

我们可以从两个维度来理解这些技术的区别：
- **横轴（LLM 优化）**：对模型本身进行多大程度的修改。从左到右，优化的程度越来越深，其中提示工程和 RAG 完全不改变模型权重，而微调则直接修改模型参数。
- **纵轴（上下文优化）**：对输入给模型的信息进行多大程度的增强。从下到上，增强的程度越来越高，其中提示工程只是优化提问方式，而 RAG 则通过引入外部知识库，极大地丰富了上下文信息。

基于此，我们的选择路径就清晰了：

1. **先尝试提示工程**：通过精心设计提示词来引导模型，适用于任务简单、模型已有相关知识的场景。
2. **再选择 RAG**：如果模型缺乏特定或实时知识而无法回答，则使用 RAG，通过外挂知识库为其提供上下文信息。
3. **最后考虑微调**：当目标是改变模型"如何做"（行为/风格/格式）而不是"知道什么"（知识）时，微调是最终且最合适的选择。例如，让模型学会严格遵循某种独特的输出格式、模仿特定人物的对话风格，或者将极其复杂的指令"蒸馏"进模型权重中。

RAG 的出现填补了通用模型与专业领域之间的鸿沟，它在解决 LLM 局限时尤其有效：

| 问题 | RAG的解决方案 |
|------|---------------|
| 静态知识局限 | 实时检索外部知识库，支持动态更新 |
| 幻觉（Hallucination） | 基于检索内容生成，错误率降低 |
| 领域专业性不足 | 引入领域特定知识库（如医疗/法律） |
| 数据隐私风险 | 本地化部署知识库，避免敏感数据泄露 |

### 2.2 关键优势
RAG 技术具有以下关键优势：

1. **准确性与可信度的双重提升**：通过引入外部检索到的参考资料，RAG 显著降低了 LLM 生成内容的错误率，并为输出提供了可追溯的依据。
2. **知识的时效性与可更新性**：外部知识库可以随时更新，确保模型能够获取最新的信息，避免了模型知识的"过期"问题。
3. **成本效益的优化**：与微调相比，RAG 无需大量的标注数据和计算资源，工程落地路径更清晰、成本更低。
4. **系统的可扩展性与灵活性**：RAG 系统的各个组件（检索模块、生成模块等）可以独立优化和扩展，适应不同场景的需求。
5. **隐私与安全的保障**：通过本地化部署知识库，RAG 可以避免敏感数据的泄露风险，满足企业的数据安全需求。

## 三、RAG 的应用场景
RAG 技术在多个领域都有广泛的应用前景：

### 3.1 智能问答系统
构建基于企业知识库的智能问答系统，为员工或客户提供准确、实时的信息查询服务。

### 3.2 文档辅助生成
帮助用户生成基于特定文档的内容，如合同、报告、论文等，确保生成内容的准确性和一致性。

### 3.3 知识管理与检索
将企业的海量文档转化为可检索的知识库，提高知识的利用率和管理效率。

### 3.4 个性化推荐
结合用户的历史行为和兴趣偏好，为用户提供个性化的信息推荐服务。

### 3.5 虚拟助手与客服
构建智能虚拟助手或客服系统，为用户提供24小时的不间断服务，提升服务质量和效率。

## 四、RAG 技术的未来发展趋势
随着技术的不断进步，RAG 系统也在朝着更加智能化、高效化的方向发展：

### 4.1 多模态 RAG
将文本、图像、音频、视频等多种模态的信息整合到 RAG 系统中，实现跨模态的信息检索和生成。

### 4.2 实时知识更新
支持对动态变化的数据源进行实时索引和检索，确保模型能够获取最新的信息。

### 4.3 个性化 RAG
根据用户的个性化需求和偏好，动态调整检索策略和生成风格，提供更加定制化的服务。

### 4.4 端到端优化
通过联合优化检索和生成模块，提高 RAG 系统的整体性能和效率。

### 4.5 轻量化 RAG
设计更加轻量化的 RAG 系统，降低部署和运行成本，使其能够在资源受限的环境中运行。

## 五、总结
RAG 技术作为一种连接大语言模型与外部知识库的桥梁，为解决 LLM 的知识局限性问题提供了一种有效的解决方案。它通过将模型内部的参数化知识与外部的非参数化知识相结合，显著提升了模型输出的准确性、时效性和可信度。

随着技术的不断发展，RAG 系统将在更多领域得到应用，并朝着更加智能化、高效化的方向发展。对于企业和开发者来说，掌握 RAG 技术将成为构建下一代智能系统的重要基础。

---

> 注：本文内容参考自 DataWhale All-in-RAG 项目，更多详细内容请访问 [https://github.com/datawhalechina/all-in-rag](https://github.com/datawhalechina/all-in-rag)。

